{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "obamaSpeechRdd: org.apache.spark.rdd.RDD[String] = data/state-of-union MapPartitionsRDD[1] at textFile at <console>:25\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val obamaSpeechRdd = sc.textFile(\"data/state-of-union\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "obamaSpeechLowerRdd: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[3] at map at <console>:26\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val obamaSpeechLowerRdd = obamaSpeechRdd.map(_.toLowerCase())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split line into a list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "obamaWordsRdd: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[359] at flatMap at <console>:30\n",
       "res68: obamaWordsRdd.type = MapPartitionsRDD[359] at flatMap at <console>:30\n"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//val obamaWordsRdd = obamaSpeechLowerRdd.flatMap(x => x.split(\"\\\\s+\")).map(_.replaceAll(\"\\\\W\",\"\")).filter(!_.equals(\"\"))\n",
    "\n",
    "val obamaWordsRdd = obamaSpeechLowerRdd.flatMap(x => x.split(\"\\\\W+\"))\n",
    "obamaWordsRdd.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stop words from the state of union speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stopWordsRdd: org.apache.spark.rdd.RDD[String] = data/stop-words/stop-word-list.txt MapPartitionsRDD[361] at textFile at <console>:29\n",
       "obamaNoStopRdd: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[365] at subtract at <console>:30\n"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val stopWordsRdd = sc.textFile(\"data/stop-words/stop-word-list.txt\")\n",
    "val obamaNoStopRdd = obamaWordsRdd.subtract(stopWordsRdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(s,537)\n",
      "(t,225)\n",
      "(america,199)\n",
      "(new,197)\n",
      "(people,176)\n",
      "(jobs,167)\n",
      "(american,154)\n",
      "(years,143)\n",
      "(americans,131)\n",
      "(work,131)\n",
      "(make,128)\n",
      "(year,127)\n",
      "(time,117)\n",
      "(let,117)\n",
      "(ve,116)\n",
      "(know,106)\n",
      "(country,105)\n",
      "(like,104)\n",
      "(world,103)\n",
      "(economy,98)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "obamaWordCoundRdd: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[367] at reduceByKey at <console>:28\n"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val obamaWordCoundRdd = obamaNoStopRdd.map((_,1)).reduceByKey(_+_)\n",
    "//obamaWordCoundRdd.coalesce(1).sortByKey().foreach(println)\n",
    "obamaWordCoundRdd.coalesce(1).sortBy(x => x._2,false).take(20).foreach(println)\n",
    "//obamaWordCoundRdd.foreach(println)\n",
    "//obamaWordCoundRdd.takeOrdered(20)(Ordering[Int].reverse.on(_._2)).foreach(println)\n",
    "/*\n",
    "(s,537)\n",
    "(t,225)\n",
    "(america,199)\n",
    "(new,197)\n",
    "(people,176)\n",
    "(jobs,167)\n",
    "(american,154)\n",
    "*/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of words that start with each letter in alphabet\n",
    "\n",
    "What is the distribution like?\n",
    "\n",
    "Instead of creating a tuple of (word, 1), create (word(0), 1) or (word.charAt(0), 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,38)\n",
      "(1,82)\n",
      "(2,64)\n",
      "(3,20)\n",
      "(4,11)\n",
      "(5,20)\n",
      "(6,12)\n",
      "(7,11)\n",
      "(8,6)\n",
      "(9,16)\n",
      "(a,5508)\n",
      "(b,2078)\n",
      "(c,2483)\n",
      "(d,1426)\n",
      "(e,1305)\n",
      "(f,1837)\n",
      "(g,845)\n",
      "(h,1663)\n",
      "(i,3019)\n",
      "(j,390)\n",
      "(k,294)\n",
      "(l,1160)\n",
      "(m,1763)\n",
      "(n,1243)\n",
      "(o,3332)\n",
      "(p,1707)\n",
      "(q,72)\n",
      "(r,1364)\n",
      "(s,3273)\n",
      "(t,7927)\n",
      "(u,551)\n",
      "(v,315)\n",
      "(w,3724)\n",
      "(y,620)\n",
      "(z,2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "startsWithRdd: org.apache.spark.rdd.RDD[(Char, Int)] = ShuffledRDD[388] at sortByKey at <console>:31\n"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val startsWithRdd = obamaWordsRdd.filter(!_.equals(\"\"))\n",
    "    .map(x=>(x.charAt(0),1))\n",
    "    .reduceByKey((x,y)=>x+y)\n",
    "    .sortByKey()\n",
    "startsWithRdd.collect().foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are some of the longest words in all the speeches?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-23 21:40:33 WARN  TransportChannelHandler:78 - Exception in connection from /10.20.8.238:55590\n",
      "java.io.IOException: Operation timed out\n",
      "\tat sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)\n",
      "\tat sun.nio.ch.IOUtil.read(IOUtil.java:192)\n",
      "\tat sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)\n",
      "\tat io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:288)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1106)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:343)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:123)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)\n",
      "\tat io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "2019-04-23 21:40:33 ERROR TransportResponseHandler:154 - Still have 1 requests outstanding when connection from /10.20.8.238:55590 is closed\n",
      "2019-04-23 21:40:33 ERROR Executor:91 - Exception in task 0.0 in stage 283.0 (TID 1042)\n",
      "java.lang.ClassCastException: cannot assign instance of scala.collection.immutable.List$SerializationProxy to field org.apache.spark.rdd.RDD.org$apache$spark$rdd$RDD$$dependencies_ of type scala.collection.Seq in instance of org.apache.spark.rdd.MapPartitionsRDD\n",
      "\tat java.io.ObjectStreamClass$FieldReflector.setObjFieldValues(ObjectStreamClass.java:2287)\n",
      "\tat java.io.ObjectStreamClass.setObjFieldValues(ObjectStreamClass.java:1417)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2293)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:431)\n",
      "\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)\n",
      "\tat sun.reflect.GeneratedMethodAccessor20.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1170)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2178)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:431)\n",
      "\tat org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)\n",
      "\tat org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:83)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "2019-04-23 21:40:33 WARN  TaskSetManager:66 - Lost task 0.0 in stage 283.0 (TID 1042, localhost, executor driver): java.lang.ClassCastException: cannot assign instance of scala.collection.immutable.List$SerializationProxy to field org.apache.spark.rdd.RDD.org$apache$spark$rdd$RDD$$dependencies_ of type scala.collection.Seq in instance of org.apache.spark.rdd.MapPartitionsRDD\n",
      "\tat java.io.ObjectStreamClass$FieldReflector.setObjFieldValues(ObjectStreamClass.java:2287)\n",
      "\tat java.io.ObjectStreamClass.setObjFieldValues(ObjectStreamClass.java:1417)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2293)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:431)\n",
      "\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)\n",
      "\tat sun.reflect.GeneratedMethodAccessor20.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1170)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2178)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:431)\n",
      "\tat org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)\n",
      "\tat org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:83)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "2019-04-23 21:40:33 ERROR TaskSetManager:70 - Task 0 in stage 283.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "ename": "org.apache.spark.SparkException",
     "evalue": " Job aborted due to stage failure: Task 0 in stage 283.0 failed 1 times, most recent failure: Lost task 0.0 in stage 283.0 (TID 1042, localhost, executor driver): java.lang.ClassCastException: cannot assign instance of scala.collection.immutable.List$SerializationProxy to field org.apache.spark.rdd.RDD.org$apache$spark$rdd$RDD$$dependencies_ of type scala.collection.Seq in instance of org.apache.spark.rdd.MapPartitionsRDD",
     "output_type": "error",
     "traceback": [
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 283.0 failed 1 times, most recent failure: Lost task 0.0 in stage 283.0 (TID 1042, localhost, executor driver): java.lang.ClassCastException: cannot assign instance of scala.collection.immutable.List$SerializationProxy to field org.apache.spark.rdd.RDD.org$apache$spark$rdd$RDD$$dependencies_ of type scala.collection.Seq in instance of org.apache.spark.rdd.MapPartitionsRDD",
      "\tat java.io.ObjectStreamClass$FieldReflector.setObjFieldValues(ObjectStreamClass.java:2287)",
      "\tat java.io.ObjectStreamClass.setObjFieldValues(ObjectStreamClass.java:1417)",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2293)",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)",
      "\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:431)",
      "\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)",
      "\tat sun.reflect.GeneratedMethodAccessor20.invoke(Unknown Source)",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)",
      "\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1170)",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2178)",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)",
      "\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:431)",
      "\tat org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)",
      "\tat org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:83)",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:121)",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)",
      "\tat java.lang.Thread.run(Thread.java:748)",
      "",
      "Driver stacktrace:",
      "  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)",
      "  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)",
      "  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)",
      "  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)",
      "  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)",
      "  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)",
      "  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)",
      "  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)",
      "  at scala.Option.foreach(Option.scala:257)",
      "  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)",
      "  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)",
      "  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)",
      "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)",
      "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)",
      "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)",
      "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)",
      "  at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
      "  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)",
      "  at org.apache.spark.rdd.RDD.collect(RDD.scala:944)",
      "  at org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:309)",
      "  at org.apache.spark.RangePartitioner.<init>(Partitioner.scala:171)",
      "  at org.apache.spark.RangePartitioner.<init>(Partitioner.scala:151)",
      "  at org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$sortByKey$1.apply(OrderedRDDFunctions.scala:62)",
      "  at org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$sortByKey$1.apply(OrderedRDDFunctions.scala:61)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
      "  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)",
      "  at org.apache.spark.rdd.OrderedRDDFunctions.sortByKey(OrderedRDDFunctions.scala:61)",
      "  ... 36 elided",
      "Caused by: java.lang.ClassCastException: cannot assign instance of scala.collection.immutable.List$SerializationProxy to field org.apache.spark.rdd.RDD.org$apache$spark$rdd$RDD$$dependencies_ of type scala.collection.Seq in instance of org.apache.spark.rdd.MapPartitionsRDD",
      "  at java.io.ObjectStreamClass$FieldReflector.setObjFieldValues(ObjectStreamClass.java:2287)",
      "  at java.io.ObjectStreamClass.setObjFieldValues(ObjectStreamClass.java:1417)",
      "  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2293)",
      "  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)",
      "  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)",
      "  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)",
      "  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)",
      "  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)",
      "  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)",
      "  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)",
      "  at java.io.ObjectInputStream.readObject(ObjectInputStream.java:431)",
      "  at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)",
      "  at sun.reflect.GeneratedMethodAccessor20.invoke(Unknown Source)",
      "  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
      "  at java.lang.reflect.Method.invoke(Method.java:498)",
      "  at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1170)",
      "  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2178)",
      "  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)",
      "  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)",
      "  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)",
      "  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)",
      "  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)",
      "  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)",
      "  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)",
      "  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)",
      "  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)",
      "  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)",
      "  at java.io.ObjectInputStream.readObject(ObjectInputStream.java:431)",
      "  at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)",
      "  at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)",
      "  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:83)",
      "  at org.apache.spark.scheduler.Task.run(Task.scala:121)",
      "  at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)",
      "  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)",
      "  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)",
      "  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)",
      "  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)",
      "  ... 1 more",
      ""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-23 21:41:48 ERROR Utils:91 - Aborting task\n",
      "java.io.IOException: Failed to connect to /10.20.8.238:55590\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$downloadClient(NettyRpcEnv.scala:368)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$openChannel$1.apply$mcV$sp(NettyRpcEnv.scala:336)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$openChannel$1.apply(NettyRpcEnv.scala:335)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$openChannel$1.apply(NettyRpcEnv.scala:335)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.openChannel(NettyRpcEnv.scala:339)\n",
      "\tat org.apache.spark.repl.ExecutorClassLoader.org$apache$spark$repl$ExecutorClassLoader$$getClassFileInputStreamFromSparkRPC(ExecutorClassLoader.scala:92)\n",
      "\tat org.apache.spark.repl.ExecutorClassLoader$$anonfun$1.apply(ExecutorClassLoader.scala:60)\n",
      "\tat org.apache.spark.repl.ExecutorClassLoader$$anonfun$1.apply(ExecutorClassLoader.scala:60)\n",
      "\tat org.apache.spark.repl.ExecutorClassLoader.findClassLocally(ExecutorClassLoader.scala:128)\n",
      "\tat org.apache.spark.repl.ExecutorClassLoader.findClass(ExecutorClassLoader.scala:82)\n",
      "\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n",
      "\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n",
      "\tat java.lang.Class.forName0(Native Method)\n",
      "\tat java.lang.Class.forName(Class.java:348)\n",
      "\tat org.apache.spark.serializer.JavaDeserializationStream$$anon$1.resolveClass(JavaSerializer.scala:67)\n",
      "\tat java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1868)\n",
      "\tat java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1751)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2042)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:431)\n",
      "\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)\n",
      "\tat sun.reflect.GeneratedMethodAccessor20.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1170)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2178)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:431)\n",
      "\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)\n",
      "\tat sun.reflect.GeneratedMethodAccessor20.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1170)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2178)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:431)\n",
      "\tat org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)\n",
      "\tat org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:83)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Operation timed out: /10.20.8.238:55590\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)\n",
      "\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)\n",
      "\tat io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)\n",
      "\t... 1 more\n",
      "Caused by: java.net.ConnectException: Operation timed out\n",
      "\t... 11 more\n",
      "2019-04-23 21:41:48 ERROR ExecutorClassLoader:91 - Failed to check existence of class $line140.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$anonfun$1 on REPL class server at spark://10.20.8.238:55590/classes\n",
      "java.io.IOException: Failed to connect to /10.20.8.238:55590\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$downloadClient(NettyRpcEnv.scala:368)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$openChannel$1.apply$mcV$sp(NettyRpcEnv.scala:336)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$openChannel$1.apply(NettyRpcEnv.scala:335)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$openChannel$1.apply(NettyRpcEnv.scala:335)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.openChannel(NettyRpcEnv.scala:339)\n",
      "\tat org.apache.spark.repl.ExecutorClassLoader.org$apache$spark$repl$ExecutorClassLoader$$getClassFileInputStreamFromSparkRPC(ExecutorClassLoader.scala:92)\n",
      "\tat org.apache.spark.repl.ExecutorClassLoader$$anonfun$1.apply(ExecutorClassLoader.scala:60)\n",
      "\tat org.apache.spark.repl.ExecutorClassLoader$$anonfun$1.apply(ExecutorClassLoader.scala:60)\n",
      "\tat org.apache.spark.repl.ExecutorClassLoader.findClassLocally(ExecutorClassLoader.scala:128)\n",
      "\tat org.apache.spark.repl.ExecutorClassLoader.findClass(ExecutorClassLoader.scala:82)\n",
      "\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n",
      "\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n",
      "\tat java.lang.Class.forName0(Native Method)\n",
      "\tat java.lang.Class.forName(Class.java:348)\n",
      "\tat org.apache.spark.serializer.JavaDeserializationStream$$anon$1.resolveClass(JavaSerializer.scala:67)\n",
      "\tat java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1868)\n",
      "\tat java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1751)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2042)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:431)\n",
      "\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)\n",
      "\tat sun.reflect.GeneratedMethodAccessor20.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1170)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2178)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:431)\n",
      "\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)\n",
      "\tat sun.reflect.GeneratedMethodAccessor20.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1170)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2178)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:431)\n",
      "\tat org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)\n",
      "\tat org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:83)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Operation timed out: /10.20.8.238:55590\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)\n",
      "\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)\n",
      "\tat io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)\n",
      "\t... 1 more\n",
      "Caused by: java.net.ConnectException: Operation timed out\n",
      "\t... 11 more\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-23 21:41:48 WARN  TaskSetManager:66 - Lost task 3.0 in stage 283.0 (TID 1045, localhost, executor driver): TaskKilled (Stage cancelled)\n",
      "2019-04-23 21:43:06 ERROR Utils:91 - Aborting task\n",
      "java.io.IOException: Failed to connect to /10.20.8.238:55590\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$downloadClient(NettyRpcEnv.scala:368)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$openChannel$1.apply$mcV$sp(NettyRpcEnv.scala:336)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$openChannel$1.apply(NettyRpcEnv.scala:335)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$openChannel$1.apply(NettyRpcEnv.scala:335)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.openChannel(NettyRpcEnv.scala:339)\n",
      "\tat org.apache.spark.repl.ExecutorClassLoader.org$apache$spark$repl$ExecutorClassLoader$$getClassFileInputStreamFromSparkRPC(ExecutorClassLoader.scala:92)\n",
      "\tat org.apache.spark.repl.ExecutorClassLoader$$anonfun$1.apply(ExecutorClassLoader.scala:60)\n",
      "\tat org.apache.spark.repl.ExecutorClassLoader$$anonfun$1.apply(ExecutorClassLoader.scala:60)\n",
      "\tat org.apache.spark.repl.ExecutorClassLoader.findClassLocally(ExecutorClassLoader.scala:128)\n",
      "\tat org.apache.spark.repl.ExecutorClassLoader.findClass(ExecutorClassLoader.scala:82)\n",
      "\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n",
      "\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n",
      "\tat java.lang.Class.forName0(Native Method)\n",
      "\tat java.lang.Class.forName(Class.java:348)\n",
      "\tat org.apache.spark.serializer.JavaDeserializationStream$$anon$1.resolveClass(JavaSerializer.scala:67)\n",
      "\tat java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1868)\n",
      "\tat java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1751)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2042)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:431)\n",
      "\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)\n",
      "\tat sun.reflect.GeneratedMethodAccessor20.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1170)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2178)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:431)\n",
      "\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)\n",
      "\tat sun.reflect.GeneratedMethodAccessor20.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1170)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2178)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:431)\n",
      "\tat org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)\n",
      "\tat org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:83)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Operation timed out: /10.20.8.238:55590\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)\n",
      "\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)\n",
      "\tat io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)\n",
      "\t... 1 more\n",
      "Caused by: java.net.ConnectException: Operation timed out\n",
      "\t... 11 more\n",
      "2019-04-23 21:43:06 ERROR ExecutorClassLoader:91 - Failed to check existence of class $line140.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$anonfun$1 on REPL class server at spark://10.20.8.238:55590/classes\n",
      "java.io.IOException: Failed to connect to /10.20.8.238:55590\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$downloadClient(NettyRpcEnv.scala:368)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$openChannel$1.apply$mcV$sp(NettyRpcEnv.scala:336)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$openChannel$1.apply(NettyRpcEnv.scala:335)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$openChannel$1.apply(NettyRpcEnv.scala:335)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.openChannel(NettyRpcEnv.scala:339)\n",
      "\tat org.apache.spark.repl.ExecutorClassLoader.org$apache$spark$repl$ExecutorClassLoader$$getClassFileInputStreamFromSparkRPC(ExecutorClassLoader.scala:92)\n",
      "\tat org.apache.spark.repl.ExecutorClassLoader$$anonfun$1.apply(ExecutorClassLoader.scala:60)\n",
      "\tat org.apache.spark.repl.ExecutorClassLoader$$anonfun$1.apply(ExecutorClassLoader.scala:60)\n",
      "\tat org.apache.spark.repl.ExecutorClassLoader.findClassLocally(ExecutorClassLoader.scala:128)\n",
      "\tat org.apache.spark.repl.ExecutorClassLoader.findClass(ExecutorClassLoader.scala:82)\n",
      "\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n",
      "\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n",
      "\tat java.lang.Class.forName0(Native Method)\n",
      "\tat java.lang.Class.forName(Class.java:348)\n",
      "\tat org.apache.spark.serializer.JavaDeserializationStream$$anon$1.resolveClass(JavaSerializer.scala:67)\n",
      "\tat java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1868)\n",
      "\tat java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1751)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2042)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:431)\n",
      "\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)\n",
      "\tat sun.reflect.GeneratedMethodAccessor20.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1170)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2178)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:431)\n",
      "\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)\n",
      "\tat sun.reflect.GeneratedMethodAccessor20.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1170)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2178)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287)\n",
      "\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211)\n",
      "\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069)\n",
      "\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573)\n",
      "\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:431)\n",
      "\tat org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)\n",
      "\tat org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:83)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Operation timed out: /10.20.8.238:55590\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)\n",
      "\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)\n",
      "\tat io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)\n",
      "\t... 1 more\n",
      "Caused by: java.net.ConnectException: Operation timed out\n",
      "\t... 11 more\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-23 21:43:07 WARN  TaskSetManager:66 - Lost task 2.0 in stage 283.0 (TID 1044, localhost, executor driver): TaskKilled (Stage cancelled)\n"
     ]
    }
   ],
   "source": [
    "val wordLengthRdd = obamaWordsRdd.map(x => (x.length(),x))\n",
    "wordLengthRdd.sortByKey().collect().foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
